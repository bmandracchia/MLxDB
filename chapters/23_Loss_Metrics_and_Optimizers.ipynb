{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training a Digit Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll explore the steps involved in building a simple digit classifier. We will:\n",
    "- Discuss the role of arrays and tensors, and introduce broadcasting, a powerful technique that makes operations on these data structures more expressive.\n",
    "- Define a suitable loss function for this classification task, and introduce the concept of mini-batches to optimize the training process.\n",
    "- Explain the mathematical operations performed by a basic neural network.\n",
    "\n",
    "By the end, we’ll combine all these pieces to create a model capable of classifying images of digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "We will build an image classifier to explore the key steps and techniques in the deep learning pipeline.\n",
    "\n",
    "In image classification, our goal is to assign a label $ y $ to each image $ X $ from a set of possible classes $ C $, where $ C $ could be categories like pet breeds, disease states, or cell types. Mathematically, we can represent this as a function $ f: X \\rightarrow y $, which maps each image to a class label. This is achieved by training a model to minimize a loss function that quantifies the difference between predicted and true labels.\n",
    "\n",
    "For binary classification (e.g., identifying the presence or absence of a disease), the output is a single probability score $ p $, with $ y = 1 $ if $ p \\geq 0.5 $ and $ y = 0 $ otherwise. For multi-class classification (e.g., identifying different types of tumors), the model outputs a vector of probabilities $ \\mathbf{p} = [p_1, p_2, \\dots, p_k] $ for each class $ k $, where $ \\sum_{i=1}^k p_i = 1 $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pixels: The Foundations of Computer Vision\n",
    "\n",
    "Our goal is to build a model that can classify an image as either a \"3\" or a \"7.\" To start, let's download a sample of the MNIST dataset that includes images of just these digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.14% [3219456/3214948 00:40&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [Path('C:/Users/biagi/.fastai/data/mnist_sample/labels.csv'),Path('C:/Users/biagi/.fastai/data/mnist_sample/train'),Path('C:/Users/biagi/.fastai/data/mnist_sample/valid')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the MNIST sample dataset\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "\n",
    "# Check the directory contents\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The MNIST dataset follows a common layout for machine learning datasets, with separate folders for the training and validation sets. Inside the training set, there are folders named for each label (3 and 7), which contain the images for each respective digit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('C:/Users/biagi/.fastai/data/mnist_sample/train/3'),Path('C:/Users/biagi/.fastai/data/mnist_sample/train/7')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, \"3\" and \"7\" are the *labels* or *targets*. Let’s take a look at a sample image of a handwritten \"3\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path for the images of \"3\"\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "\n",
    "# Open and display an example image\n",
    "im3_path = threes[1]\n",
    "im3 = Image.open(im3_path)\n",
    "im3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Images in Python are often represented by the `Image` class from the *Python Imaging Library* (PIL). Converting an image to a numerical format, like a NumPy array or PyTorch tensor, allows us to perform mathematical operations directly on the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each pixel in the image has a value between 0 and 255, where 0 represents black and 255 represents white, with shades of gray in between. Converting the image to a PyTorch tensor allows us to manipulate and process it further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pixel Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple baseline model, let's calculate the average pixel values for all images of \"3\" and \"7\" separately. This will give us an \"ideal\" version of each digit, which we can use for comparison. To classify an image, we’ll check which of these ideal representations the image most closely resembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load images of 3s and 7s as tensors\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in (path/'train'/'7').ls().sorted()]\n",
    "\n",
    "# Stack tensors and normalize\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "\n",
    "# Calculate the average image (mean) for each digit\n",
    "mean3 = stacked_threes.mean(0)\n",
    "mean7 = stacked_sevens.mean(0)\n",
    "\n",
    "# Display the \"ideal\" 3 and 7\n",
    "show_image(mean3)\n",
    "show_image(mean7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach provides a very basic model: for any new image, we calculate its \"distance\" from the average 3 and average 7, then classify it as the closest match. Distance can be calculated using either:\n",
    "- **Mean Absolute Difference** (L1 norm)\n",
    "- **Root Mean Squared Error** (L2 norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the distance to the ideal 3 is smaller, we classify the image as a 3, otherwise as a 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try both of these now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_3_abs = (a_3 - mean3).abs().mean()\n",
    "dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\n",
    "dist_3_abs,dist_3_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_7_abs = (a_3 - mean7).abs().mean()\n",
    "dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\n",
    "dist_7_abs,dist_7_sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In both cases, the distance between our 3 and the \"ideal\" 3 is less than the distance to the ideal 7. So our simple model will give the right prediction in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ">  Intuitively, the difference between L1 norm and mean squared error (MSE) is that the latter will penalize bigger mistakes more heavily than the former (and be more lenient with small mistakes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model, we need a way to measure how well it’s doing. This measurement is called a **metric**. Metrics are calculated based on the model’s predictions compared to the actual labels in the dataset. For classification tasks like this, a common metric is **accuracy**.\n",
    "\n",
    "In our case, we want to determine if each image is classified correctly as either a \"3\" or a \"7.\" Accuracy for this task can be computed by:\n",
    "1. Calculating the model’s prediction for each image.\n",
    "2. Checking if the prediction matches the actual label.\n",
    "3. Averaging these correct/incorrect results across the entire dataset.\n",
    "\n",
    "We have two sets of validation images: one for 3s and one for 7s. Let’s load and prepare these validation sets as tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and normalize validation sets\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()]).float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]).float()/255\n",
    "\n",
    "# Check shapes of validation tensors\n",
    "valid_3_tens.shape, valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tensor has the shape `[number_of_images, height, width]`, where:\n",
    "- `valid_3_tens` has 1,010 images of 3s.\n",
    "- `valid_7_tens` has 1,028 images of 7s.\n",
    "  \n",
    "This setup allows us to test our function across both categories and compute accuracy based on all validation images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tensors and Broadcasting\n",
    "\n",
    "Tensors are multidimensional arrays that enable fast computation in PyTorch. Unlike Python lists, which are slow, tensors allow us to perform large-scale mathematical operations quickly.\n",
    "\n",
    "For instance, let's add 1 to each element in a tensor and multiply it by another tensor, without any Python loops:\n",
    "\n",
    "```python\n",
    "tns = tensor([[1,2,3],[4,5,6]])\n",
    "tns + 1\n",
    "tns * 1.5\n",
    "```\n",
    "\n",
    "Broadcasting is a powerful technique that allows us to perform operations between tensors of different shapes. For example, subtracting an \"ideal\" digit from each image in a batch is possible because PyTorch will \"broadcast\" the ideal digit to match the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Distance Function with Broadcasting\n",
    "\n",
    "To classify an image, we need to calculate its \"distance\" from the \"ideal\" 3 and 7 (the averages we calculated earlier). A useful function for calculating this distance is **mean absolute error** (MAE).\n",
    "\n",
    "With broadcasting, we can apply the same distance calculation to an entire set of images without writing loops. Here’s our distance function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1280)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define distance function using broadcasting\n",
    "def mnist_distance(a, b): \n",
    "    return (a - b).abs().mean((-1, -2))\n",
    "\n",
    "# Calculate distance from an example image to the ideal 3\n",
    "a_3 = valid_3_tens[0]\n",
    "mnist_distance(a_3, mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass `valid_3_tens` (all 3s in the validation set) and `mean3` (the ideal 3) to this function, broadcasting automatically expands `mean3` to match the shape of `valid_3_tens`, calculating the distance for each image in the set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate distance for all 3s in the validation set\n",
    "valid_3_dist = mnist_distance(valid_3_tens, mean3)\n",
    "valid_3_dist.shape  # Output should be a vector of distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting makes this possible by \"stretching\" `mean3` to align with each image in `valid_3_tens`, allowing the distance function to operate on all images simultaneously. This avoids the need for loops and makes the computation faster and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying an Image with Distance\n",
    "\n",
    "To classify a new image, we compare its distance to `mean3` and `mean7`. If it’s closer to `mean3`, we classify it as a 3; if it’s closer to `mean7`, we classify it as a 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define classification function\n",
    "def is_3(x): \n",
    "    return mnist_distance(x, mean3) < mnist_distance(x, mean7)\n",
    "\n",
    "# Test classification on a sample 3\n",
    "is_3(a_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the validation set, we can use broadcasting to classify every image at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False,  True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify all 3s in the validation set\n",
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy\n",
    "\n",
    "To compute accuracy, we calculate the proportion of correct predictions:\n",
    "- For images of 3s, we check if the model predicted 3 (output is `True`).\n",
    "- For images of 7s, we check if the model predicted 7 (output is `False`).\n",
    "\n",
    "Here’s how to calculate accuracy for each set and the overall accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9854), tensor(0.9511))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy for each digit\n",
    "accuracy_3s = is_3(valid_3_tens).float().mean()  # Accuracy on 3s\n",
    "accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()  # Accuracy on 7s\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = (accuracy_3s + accuracy_7s) / 2\n",
    "accuracy_3s, accuracy_7s, overall_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `accuracy_3s` and `accuracy_7s` represent the accuracy for classifying 3s and 7s, respectively. By averaging these, we get an overall measure of the model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Loss Function\n",
    "\n",
    "In deep learning, the loss function is a critical component used to guide the training process. It quantifies how well our model’s predictions match the target values (labels), allowing us to improve the model by minimizing this loss over successive iterations.\n",
    "\n",
    "Our goal here is to create a loss function that:\n",
    "1. Produces a value reflecting how far the model's predictions are from the true labels.\n",
    "2. Has a gradient that can guide the optimization process, making it possible to update the model's parameters effectively.\n",
    "\n",
    "### Why Not Use Accuracy as a Loss Function?\n",
    "\n",
    "A straightforward choice for measuring model performance is **accuracy**, which calculates the proportion of correct predictions. However, accuracy is unsuitable as a loss function for two reasons:\n",
    "1. **Flat gradients**: Small changes in weights often do not affect accuracy, because the predictions remain classified the same way (correct or incorrect). This causes \"flat\" gradients, making it difficult to improve the model.\n",
    "2. **Discrete metric**: Accuracy is a discrete measure that doesn’t capture \"how wrong\" a prediction is. For instance, if the model is very close to the correct answer, accuracy won’t reflect this, but a good loss function should.\n",
    "\n",
    "For these reasons, accuracy is often used as a **metric** (to evaluate the model’s performance), while the **loss function** drives the learning process.\n",
    "\n",
    "### Defining a Loss Function for Binary Classification\n",
    "\n",
    "In our MNIST task, we are trying to classify images as either a \"3\" or a \"7.\" We can treat this as a binary classification problem:\n",
    "- **1** for images of \"3\".\n",
    "- **0** for images of \"7\".\n",
    "\n",
    "Our goal is to ensure that the model outputs values close to 1 for images of \"3\" and values close to 0 for images of \"7.\" A common approach in binary classification is to use the **mean absolute error** or **cross-entropy loss**.\n",
    "\n",
    "In this example, we'll use a custom function that measures the distance between the model's predictions and the true labels, ensuring that:\n",
    "- For images of \"3\" (target 1), the prediction is close to 1.\n",
    "- For images of \"7\" (target 0), the prediction is close to 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Simple Loss Function\n",
    "\n",
    "Suppose we have three images with labels `[1, 0, 1]` (representing \"3,\" \"7,\" and \"3\"). Let's say our model’s predictions are `[0.9, 0.4, 0.2]`. These predictions mean:\n",
    "- The model is confident the first image is a 3.\n",
    "- The model is slightly confident that the second image is a 7.\n",
    "- The model incorrectly predicts the third image as a 7.\n",
    "\n",
    "Here’s a simple loss function to measure how far the predictions are from the target labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample targets and predictions\n",
    "targets = tensor([1, 0, 1])\n",
    "predictions = tensor([0.9, 0.4, 0.2])\n",
    "\n",
    "# Define the MNIST loss function\n",
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets == 1, 1 - predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function:\n",
    "- `torch.where(targets == 1, 1 - predictions, predictions)` calculates the distance between each prediction and the target (1 or 0).\n",
    "- If `targets == 1` (for a 3), we calculate `1 - prediction` to measure how close the prediction is to 1.\n",
    "- If `targets == 0` (for a 7), we simply use `prediction` to measure how close it is to 0.\n",
    "- We then take the mean of all these distances to get the overall loss.\n",
    "\n",
    "Let’s test it with our example values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate loss\n",
    "mnist_loss(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lower loss indicates that the predictions are closer to the targets. For instance, if we change the prediction for the third image from `0.2` to `0.8`, which is closer to the target of 1, the loss decreases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2333)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(tensor([0.9, 0.4, 0.8]), targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring Predictions are Between 0 and 1 with the Sigmoid Function\n",
    "\n",
    "To use the loss function effectively, we need to ensure that predictions fall between 0 and 1. This can be done using the **sigmoid function**, defined as:\n",
    "\n",
    "$$ \\text{sigmoid}(x) = \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "The sigmoid function squashes any input to a range between 0 and 1, making it perfect for binary classification tasks. In PyTorch, we can use `torch.sigmoid` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the sigmoid function (PyTorch version)\n",
    "def sigmoid(x): return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Plot the sigmoid function\n",
    "import matplotlib.pyplot as plt\n",
    "x = torch.linspace(-4, 4, 100)\n",
    "plt.plot(x, sigmoid(x))\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output (0 to 1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function maps any real-valued input to a value between 0 and 1, which means that predictions can now represent probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the Loss Function with Sigmoid\n",
    "\n",
    "We can update our `mnist_loss` function to first apply the sigmoid to the predictions. This ensures that the loss function works even if the model outputs are not constrained between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated MNIST loss function with sigmoid\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets == 1, 1 - predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Do We Need a Separate Loss Function?\n",
    "\n",
    "The key difference between **metrics** (like accuracy) and **loss functions** is their purpose:\n",
    "- **Metrics**: Used to evaluate model performance, providing a number that indicates how well the model performs on a specific task. Metrics don’t need to be differentiable, as they’re not used in the optimization process.\n",
    "- **Loss Functions**: Guide the learning process by calculating gradients, which indicate how to adjust model parameters to improve performance. Loss functions must be smooth and differentiable, as their derivatives are used in optimization.\n",
    "\n",
    "By using this custom loss function, we provide a signal that tells the model to get closer to correct answers, even when predictions are slightly off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with Stochastic Gradient Descent (SGD) and Mini-Batches\n",
    "\n",
    "In machine learning, **Stochastic Gradient Descent (SGD)** is an optimization technique used to minimize the loss function, which guides the learning process of a model. Unlike regular **Gradient Descent**, which computes the gradient of the loss with respect to each parameter over the entire dataset, SGD approximates this by computing gradients over small, random subsets of the data called **mini-batches**.\n",
    "\n",
    "SGD allows for faster training and can lead to better generalization due to the randomness in mini-batch sampling, which helps the model avoid getting stuck in certain local minima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Why Use Mini-Batches? \n",
    "\n",
    "Using mini-batches instead of the whole dataset or a single data item for each gradient update has several advantages:\n",
    "\n",
    "1. **Faster Computation**: Calculating gradients over the entire dataset can be slow, especially for large datasets. Mini-batches allow us to update model parameters more frequently without waiting to process the whole dataset.\n",
    "   \n",
    "2. **Stable Gradient Estimates**: A single data item may produce a noisy and unstable gradient estimate, while the entire dataset provides a more accurate but computationally expensive estimate. Mini-batches provide a balance between these two, resulting in more stable gradient updates.\n",
    "\n",
    "3. **Optimized GPU Utilization**: When using hardware accelerators like GPUs, mini-batches allow for parallel computations, maximizing the utilization of these resources.\n",
    "\n",
    "4. **Improved Generalization**: The random sampling of mini-batches introduces stochasticity (randomness) in parameter updates, helping the model avoid overfitting and improve generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Batch Size\n",
    "\n",
    "At the heart of the decision to use minibatches is computational efficiency.\n",
    "Processing single observations requires us to perform many single matrix-vector (or even vector-vector)\n",
    "multiplications, which is quite expensive and which incurs a significant\n",
    "overhead on behalf of the underlying deep learning framework. This\n",
    "applies both to evaluating a network when applied to data (often\n",
    "referred to as inference) and when computing gradients to update\n",
    "parameters. That is, this applies whenever we perform\n",
    "$\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta_t \\mathbf{g}_t$ where\n",
    "\n",
    "$$ \\mathbf{g}_t = \\partial_{\\mathbf{w}} f(\\mathbf{x}_{t}, \\mathbf{w}) $$\n",
    "\n",
    "We can increase the *computational* efficiency of this operation by\n",
    "applying it to a minibatch of observations at a time. That is, we\n",
    "replace the gradient $\\mathbf{g}_t$ over a single observation by\n",
    "one over a small batch\n",
    "\n",
    "$$ \\mathbf{g}_t = \\partial_{\\mathbf{w}} \\frac{1}{|\\mathcal{B}_t|} \\sum_{i \\in \\mathcal{B}_t} f(\\mathbf{x}_{i}, \\mathbf{w}) $$\n",
    "\n",
    "Let's see what this does to the statistical properties of\n",
    "$\\mathbf{g}_t$: since both $\\mathbf{x}_t$ and also all\n",
    "elements of the minibatch $\\mathcal{B}_t$ are drawn uniformly at\n",
    "random from the training set, the expectation of the gradient remains\n",
    "unchanged. The variance, on the other hand, is reduced significantly.\n",
    "Since the minibatch gradient is composed of\n",
    "$b \\stackrel{\\textrm{def}}{=} |\\mathcal{B}_t|$ independent\n",
    "gradients which are being averaged, its standard deviation is reduced by\n",
    "a factor of $b^{-\\frac{1}{2}}$. This, by itself, is a good thing,\n",
    "since it means that the updates are more reliably aligned with the full\n",
    "gradient.\n",
    "\n",
    "Naively this would indicate that choosing a large minibatch\n",
    "$\\mathcal{B}_t$ would be universally desirable. Alas, after some\n",
    "point, the additional reduction in standard deviation is minimal when\n",
    "compared to the linear increase in computational cost. So, we may say that:\n",
    "- **Larger batch sizes** produce more stable gradient estimates, but training may be slower per update step.\n",
    "- **Smaller batch sizes** allow for faster updates but may produce noisy gradients, which can make training less stable.\n",
    "\n",
    "Then, in practice we pick a minibatch that is large enough to offer good computational\n",
    "efficiency while still fitting into the memory of a GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Shuffling the Data\n",
    "\n",
    "To prevent the model from seeing data in a fixed order, which could introduce unwanted patterns in updates, it’s standard practice to shuffle the dataset before dividing it into mini-batches. Shuffling the data in each epoch ensures that the model doesn’t rely on any specific order in the data.\n",
    "\n",
    "PyTorch provides the `DataLoader` class, which automatically handles shuffling and mini-batch creation. Here’s a simple example of using `DataLoader` to create mini-batches from a dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 3,  7,  0,  8, 10]),\n",
       " tensor([ 4, 17,  1, 16, 12]),\n",
       " tensor([ 5, 15, 13, 11, 19]),\n",
       " tensor([14,  6,  9,  2, 18])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Sample data for demonstration\n",
    "data = range(20)\n",
    "\n",
    "# Create a DataLoader with batch size 5 and shuffling enabled\n",
    "dl = DataLoader(data, batch_size=5, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `dl` creates batches of size 5, and the `shuffle=True` argument ensures that the data order is randomized with each epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Applying Mini-Batches to Images and Labels\n",
    "\n",
    "For our MNIST classification task, we need to process both the images (features) and the labels (targets). Here’s how we can create a `DataLoader` for the MNIST dataset:\n",
    "\n",
    "1. **Combine images and labels** into a PyTorch Dataset.\n",
    "2. **Use a DataLoader** to create mini-batches of this dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset for training\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28 * 28)\n",
    "train_y = tensor([1] * len(stacked_threes) + [0] * len(stacked_sevens)).unsqueeze(1)\n",
    "train_dataset = list(zip(train_x, train_y))\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "\n",
    "# Create the DataLoader for mini-batch processing\n",
    "batch_size = 256\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `DataLoader` here will yield mini-batches of 256 images and their corresponding labels, shuffling the dataset in each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Implementing an SGD Step with Mini-Batches\n",
    "\n",
    "For each mini-batch, we need to:\n",
    "1. **Calculate predictions** based on the current model parameters.\n",
    "2. **Compute the loss** to see how far these predictions are from the true labels.\n",
    "3. **Calculate gradients** with respect to each parameter.\n",
    "4. **Update parameters** by subtracting a small proportion (learning rate) of the gradient from each parameter.\n",
    "\n",
    "Here’s an implementation of one epoch of SGD with mini-batches:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training loop for one epoch\n",
    "def train_epoch(model, train_dl, optimizer):\n",
    "    for xb, yb in train_dl:\n",
    "        # Forward pass: calculate predictions\n",
    "        preds = model(xb)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = mnist_loss(preds, yb)\n",
    "        \n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters and zero gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Updating Parameters with `optimizer.step()`\n",
    "\n",
    "The line `optimizer.step()` updates the parameters using the computed gradients. We then use `optimizer.zero_grad()` to reset gradients before the next mini-batch; otherwise, PyTorch accumulates gradients, which would lead to incorrect updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Mini-Batch Accuracy Calculation\n",
    "\n",
    "To evaluate the model’s performance, we can compute the accuracy on the validation set. For each mini-batch, we check if each prediction matches the true label and average these correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy calculation function\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds > 0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "# Validation accuracy calculation\n",
    "def validate_epoch(model, valid_dl):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Putting It All Together\n",
    "\n",
    "We can now use these functions to train our model over several epochs, updating the parameters based on each mini-batch and calculating the accuracy on the validation set at the end of each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 0.9657\n",
      "Epoch 2 accuracy: 0.9687\n",
      "Epoch 3 accuracy: 0.9691\n",
      "Epoch 4 accuracy: 0.9691\n",
      "Epoch 5 accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = nn.Linear(28*28, 1)  # Simple linear model for demonstration\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    train_epoch(model, train_dl, optimizer)\n",
    "    print(f\"Epoch {epoch+1} accuracy:\", validate_epoch(model, valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Optimizer\n",
    "\n",
    "An **optimizer** is an essential component in training a neural network, responsible for updating the model's parameters (weights and biases) based on the computed gradients. This process is typically done after each mini-batch, where the optimizer adjusts the parameters in the direction that minimizes the loss function.\n",
    "\n",
    "### Why Do We Need an Optimizer?\n",
    "\n",
    "In our previous section, we implemented Stochastic Gradient Descent (SGD) manually by:\n",
    "1. Calculating gradients for each parameter using backpropagation.\n",
    "2. Subtracting a fraction of the gradient (scaled by the learning rate) from each parameter.\n",
    "\n",
    "While this process works, it can be simplified and optimized further using dedicated optimizers. PyTorch provides several built-in optimizers, each with different strategies for updating parameters. Using these optimizers streamlines the code and allows us to experiment with different optimization techniques easily.\n",
    "\n",
    "### Common Optimizers in Deep Learning\n",
    "\n",
    "1. **SGD (Stochastic Gradient Descent)**: Updates parameters by subtracting a fraction of the gradient. This method is simple but can be slow and may oscillate around local minima.\n",
    "  \n",
    "2. **Momentum-based SGD**: Builds on SGD by accumulating gradients in the direction of steepest descent, which helps accelerate convergence. \n",
    "\n",
    "3. **Adam (Adaptive Moment Estimation)**: Uses adaptive learning rates for each parameter, combining the ideas of momentum and adaptive learning rates, making it popular for many deep learning applications.\n",
    "\n",
    "For this section, we'll start by creating a basic custom optimizer similar to SGD, then show how to use PyTorch’s built-in optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Basic Optimizer\n",
    "\n",
    "Let’s define a simple optimizer called `BasicOptim` that implements standard SGD. This optimizer will:\n",
    "1. Store the parameters to be updated.\n",
    "2. Take a step size (learning rate) to scale the updates.\n",
    "3. Include a `step` method to update each parameter by subtracting the product of the gradient and learning rate.\n",
    "4. Reset gradients after each update to avoid accumulating them.\n",
    "\n",
    "Here’s an implementation of a basic optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom basic optimizer\n",
    "class BasicOptim:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)  # Parameters to optimize\n",
    "        self.lr = lr                # Learning rate\n",
    "    \n",
    "    def step(self):\n",
    "        # Update each parameter by its gradient\n",
    "        for p in self.params:\n",
    "            p.data -= p.grad.data * self.lr\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        # Set gradients to None for each parameter\n",
    "        for p in self.params:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Using `BasicOptim` with a Model\n",
    "\n",
    "To use this optimizer, we pass the model’s parameters to `BasicOptim` and specify a learning rate. Here’s a simple training loop that demonstrates how to use this custom optimizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "model = nn.Linear(28*28, 1)  # Simple linear model for demonstration\n",
    "opt = BasicOptim(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop for one epoch\n",
    "for xb, yb in train_dl:\n",
    "    # Forward pass: calculate predictions\n",
    "    preds = model(xb)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    \n",
    "    # Backward pass: compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters and zero gradients\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "- `opt.step()` updates each parameter by subtracting the scaled gradient.\n",
    "- `opt.zero_grad()` resets gradients for each parameter, ensuring that gradients from one mini-batch don’t interfere with the next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PyTorch’s Built-in Optimizers\n",
    "\n",
    "While `BasicOptim` demonstrates the core concept of SGD, PyTorch provides a built-in `SGD` optimizer, which includes additional features like momentum. Using PyTorch’s `torch.optim` library simplifies optimization and provides more options.\n",
    "\n",
    "Here’s an example of using PyTorch’s built-in `SGD` optimizer with momentum:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = nn.Linear(28*28, 1)\n",
    "opt = SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for xb, yb in train_dl:\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PyTorch’s `SGD` optimizer, we only need to specify the learning rate and optionally, a momentum factor. The optimizer handles both the parameter updates and gradient reset internally.\n",
    "\n",
    "### Switching to the Adam Optimizer\n",
    "\n",
    "Adam (Adaptive Moment Estimation) is another popular optimizer that automatically adjusts learning rates for each parameter based on historical gradients and updates. This approach often improves convergence, especially in deep networks.\n",
    "\n",
    "Switching to Adam requires only a change in the optimizer initialization, while the training loop remains the same:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = nn.Linear(28*28, 1)\n",
    "opt = Adam(model.parameters(), lr=0.001)  # Lower learning rate for Adam\n",
    "\n",
    "# Training loop\n",
    "for xb, yb in train_dl:\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "With Adam, you typically use a lower learning rate (e.g., `0.001`) than with SGD, as Adam adapts the learning rate dynamically during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastai library simplifies training by integrating the optimizer, loss function, and metrics within a single class, the `Learner`. To use `Learner`, we need to:\n",
    "1. Create a `DataLoaders` object from our training and validation data.\n",
    "2. Pass the model, optimizer, loss function, and metrics to `Learner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.112948</td>\n",
       "      <td>0.086621</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.080888</td>\n",
       "      <td>0.063943</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.062337</td>\n",
       "      <td>0.053072</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051248</td>\n",
       "      <td>0.046404</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.043826</td>\n",
       "      <td>0.041867</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038403</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034838</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.031702</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029177</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.027235</td>\n",
       "      <td>0.030236</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import Learner, DataLoaders, Adam \n",
    "\n",
    "# Create DataLoaders\n",
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "# Initialize Learner with model, optimizer, and metrics\n",
    "learn = Learner(dls, model, opt_func=Adam, loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "\n",
    "# Train model using fit\n",
    "learn.fit(10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `Learner`, we can use the `fit` method to train our model over multiple epochs, making it easier to manage training while automatically handling optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adding a Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have only used linear transformations, which are limited in their capacity to capture complex patterns. Adding a **nonlinear activation function** like the *ReLU* (Rectified Linear Unit) between layers gives our model the ability to approximate more complex functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple neural network\n",
    "simple_net = nn.Sequential(nn.Linear(28*28, 1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=Adam,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.350354</td>\n",
       "      <td>0.307095</td>\n",
       "      <td>0.866536</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.309842</td>\n",
       "      <td>0.287336</td>\n",
       "      <td>0.912659</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292670</td>\n",
       "      <td>0.279801</td>\n",
       "      <td>0.929343</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.275418</td>\n",
       "      <td>0.937193</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.276669</td>\n",
       "      <td>0.272627</td>\n",
       "      <td>0.940628</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.952895</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.270921</td>\n",
       "      <td>0.268845</td>\n",
       "      <td>0.952404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.267622</td>\n",
       "      <td>0.957311</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.266692</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.955839</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265534</td>\n",
       "      <td>0.265906</td>\n",
       "      <td>0.963199</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.264709</td>\n",
       "      <td>0.265318</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.264081</td>\n",
       "      <td>0.264861</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.262702</td>\n",
       "      <td>0.264238</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.261738</td>\n",
       "      <td>0.263872</td>\n",
       "      <td>0.969087</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.262061</td>\n",
       "      <td>0.263767</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.261289</td>\n",
       "      <td>0.263374</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.260988</td>\n",
       "      <td>0.263057</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>0.262870</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.260101</td>\n",
       "      <td>0.262619</td>\n",
       "      <td>0.971541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.260612</td>\n",
       "      <td>0.262189</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.259833</td>\n",
       "      <td>0.262367</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.259831</td>\n",
       "      <td>0.262024</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.259971</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.259046</td>\n",
       "      <td>0.261707</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.259220</td>\n",
       "      <td>0.261573</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.261645</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.258644</td>\n",
       "      <td>0.261260</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.261341</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.259515</td>\n",
       "      <td>0.261156</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.258409</td>\n",
       "      <td>0.261124</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.259996</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.259218</td>\n",
       "      <td>0.260876</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.259217</td>\n",
       "      <td>0.260877</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.259145</td>\n",
       "      <td>0.260698</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.258376</td>\n",
       "      <td>0.260633</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.258933</td>\n",
       "      <td>0.260632</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.258818</td>\n",
       "      <td>0.260599</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.258597</td>\n",
       "      <td>0.260769</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.259025</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "learn.fit(40, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The training process is recorded in `learn.recorder`, with the table of output stored in the `values` attribute, so we can plot the accuracy over training as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2), scaley=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can view the final accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9779195189476013"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
